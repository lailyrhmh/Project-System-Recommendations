# -*- coding: utf-8 -*-
"""Project System Recommendations.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LW-ZgY2Uc11A_iUyLVkxMLAyf-HkVTPv

# **System Recommendations Movies and TV Show Netflix**

---
*by Laily Rachmah*

Dataset dapat di unduh melalui [tautan ini](https://www.kaggle.com/datasets/shivamb/netflix-shows?datasetId=434238&searchQuery=recom)

# Import Necessary Library
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')

import tensorflow as tf

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

"""# Data Understanding

---
Dataset memiliki 12 feature yaitu
*   show_id
*   type
*   title
*   director
*   cast
*   country
*   date_added
*   release_year
*   rating
*   duration_ms
*   listed_in
*   description

Pada 12 feature tersebut, dalam sistem rekomendasi ini hanya menggunakan type, title, listed_in dan description.


Berikut rincian 4 feature yang digunakan

*   type : tipe konten berupa Movie atau TV Show
*   Title : judul konten
*   listed_in : kategori atau genre konten
*   description : deskripsi singkat dari konten

## Data Loading
"""

data = pd.read_csv('/content/netflix_titles.csv')
data

"""## Remove feature yang tidak digunakan"""

data = data.drop(['show_id', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration'], axis=1)
data.head()

"""# Exploratory Data Analysis (EDA)

---

> ## Deskripsi Variabel


Informasi data
"""

data.info()

"""Memiliki 3 column dan 8807 row data dengan tipe object

> ## Missing Value
"""

data.isna().sum()

"""Tidak ada missing value/data null

> ## Duplicate
"""

data.duplicated().sum()

"""Tidak ada data duplikat

> ## Univariate Exploratory Data Analysis

### Distribusi _type_ Movies dan TV Show
"""

plt.figure(figsize=(15,7))
labels = data['type'].value_counts(sort = True).index
sizes = data['type'].value_counts(sort = True)
plt.pie(sizes,labels=labels,autopct='%1.1f%%', startangle=270,)
plt.title('Distribution of Movie/TV Show',size = 20)
plt.show()

"""Data Movie dengan jumlah 69.6% dan TV Show dengan jumlah 30.4% dari seluruh data

### Distribusi Berdasarkan Genre

Mengambil nilai unik dari feature listed_in dengan split data dan dimasukkan kedalam list genres
"""

data_genre = data.drop(['description'], axis=1)
genres=[]
for i in range(len(data_genre.listed_in)):
    for x in data_genre.listed_in[i].split(', '):
        if x not in genres:
            genres.append(x)
genres

"""Melakukan encoding data pada dataframe agar memudahkan untuk menghitung jumlah konten berdasarkan genre"""

for x in genres:
    data_genre[x] = 0

for i in range(len(data_genre.listed_in)):
    for x in data_genre.listed_in[i].split(', '):
        data_genre[x][i]=1

data_genre.head()

"""Mengambil jumlah genre dari dataframe sebelumnya dan dimasukkan kedalam list genre_sum"""

genre_sum = list(data_genre.iloc[:,3:].sum())
genre_sum

"""Dimasukkan kedalam dataframe baru dengan nilai genres dan genre_sum kemudian dilakukan visualisasi data menggunakan barplot"""

data_genre_new = {'genre': pd.Series(genres),
                  'total': pd.Series(genre_sum)}

plt.figure(figsize=(15,15))
sns.barplot(y='genre', x='total', data=data_genre_new)
plt.title('Distribution of Movie/TV Show', fontsize=25, pad=20)
plt.tight_layout()
plt.show()

"""Dapat dilihat data terbanyak yaitu ada pada genre International Movies kemudian yang ke-dua yaitu Dramas dst.

### Word Popular pada _description_ dengan WordCloud
"""

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
plt.rcParams['figure.figsize'] = (13, 13)
wordcloud = WordCloud(stopwords=STOPWORDS, width = 1000, background_color='white', height = 1000, max_words = 121).generate(' '.join(data['description']))
plt.imshow(wordcloud)
plt.axis('off')
plt.title('Most Popular Words in Description',fontsize = 20, pad=25)
plt.show()

"""Kata populer teratas yaitu life dan find dst.

> ## Data Preprocessing

### Membagi Data Berdasarkan _type_ Movie dan TV Show
"""

movies = data[data['type'] == 'Movie'].reset_index()
movies.head()

tv = data[data['type'] == 'TV Show'].reset_index()
tv.head()

"""### Menghilangkan Stop Word dan Lemmatization pada _description_ Konten"""

stop_word = set(stopwords.words('english'))
lemmatizer = nltk.stem.WordNetLemmatizer()

"""Stop word dan lemmatization pada data Movie"""

movies['description'] = movies['description'].apply(lambda x:' '.join([word if word in stop_word else lemmatizer.lemmatize(word) for word in x.split()]))
movies

"""Stop word dan lemmatization pada data TV Show"""

tv['description'] = tv['description'].apply(lambda x:' '.join([word if word in stop_word else lemmatizer.lemmatize(word) for word in x.split()]))
tv

"""### Membuat Kolom Baru Untuk Menampung Nilai Dari _listed_in_ dan _description_ Untuk Modelling"""

movies['text'] = movies['listed_in'] + ' ' + movies['description']

tv['text'] = tv['listed_in'] + ' ' + tv['description']

"""# Model Development

---

> ## Content-Based Filtering

### TF-IDF Vectorizer

Menggunakan parameter min_df untuk menghilangkan term yang jarang muncul
"""

tfidf = TfidfVectorizer(min_df = 0.01)

"""Dilakukan fit data pada Movie dan Lihat cetak feature"""

tfidf.fit(movies['text'])
tfidf.get_feature_names()

"""Dilakukan fit data pada TV Show dan Lihat cetak feature"""

tfidf.fit(tv['text'])
tfidf.get_feature_names()

"""### Melakukan Fit dan Tranform data ke Dalam Matrix

Pada data Movie
"""

tfidf_movies_matrix = tfidf.fit_transform(movies['text'])
tfidf_movies_matrix.shape

"""Pada data TV Show"""

tfidf_tv_matrix = tfidf.fit_transform(tv['text'])
tfidf_tv_matrix.shape

"""### Menghitung Cosine Similarity

Pada data Movie
"""

cos_sim_movies = cosine_similarity(tfidf_movies_matrix)
cos_sim_movies

"""Pada data TV Show"""

cos_sim_tv = cosine_similarity(tfidf_tv_matrix)
cos_sim_tv

"""### Membuat Dataframe Baru Berdasarkan Cosine Similarity

Dataframe untuk Movie
"""

cosine_sim_mvs = pd.DataFrame(cos_sim_movies, index=movies['title'], columns=movies['title'])
print('Shape:', cosine_sim_mvs.shape)
 

cosine_sim_mvs.sample(5, axis=1).sample(10, axis=0)

"""Dataframe untuk TV Show"""

cosine_sim_tv = pd.DataFrame(cos_sim_tv, index=tv['title'], columns=tv['title'])
print('Shape:', cosine_sim_mvs.shape)
 

cosine_sim_tv.sample(5, axis=1).sample(10, axis=0)

"""### Uji Coba Rekomendasi

> Mendapatkan Rekomendasi Video Berdasarkan Tipe

Fungsi rekomendasi movie
"""

def movies_recommendations(title, similarity_data=cosine_sim_mvs, items=movies[['title', 'listed_in', 'description']], k=10):
    index = similarity_data.loc[:,title].to_numpy().argpartition(
        range(-1, -k, -1))
    
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    closest = closest.drop(title, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""Fungsi rekomendasi TV Show"""

def tv_recommendations(title, similarity_data=cosine_sim_tv, items=tv[['title', 'listed_in', 'description']], k=10):
    index = similarity_data.loc[:,title].to_numpy().argpartition(
        range(-1, -k, -1))
    
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    closest = closest.drop(title, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""> Rekomendasi Movie

Cek data Movie
"""

movies[movies.title.eq('Bugs')]

"""Menguji coba model Movie rekomendasi content-based filtering"""

movies_recommendations('Bugs')

"""> Rekomendasi TV Show

Cek data TV Show
"""

tv[tv.title.eq('Cocomong')]

"""Menguji coba model TV Show rekomendasi content-based filtering"""

tv_recommendations('Cocomong')